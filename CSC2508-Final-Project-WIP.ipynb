{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "WX1gSPMwudHg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WX1gSPMwudHg",
        "outputId": "500c2689-e96c-44cb-aaa8-3444208a30bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/CSC2508\n",
            "/content/drive/MyDrive/CSC2508/CSC2508_final_project\n",
            "Fetching submodule BLIP\n",
            "Already up to date.\n",
            "Requirement already satisfied: transformers==4.16.0 in /usr/local/lib/python3.10/dist-packages (4.16.0)\n",
            "Requirement already satisfied: timm==0.4.12 in /usr/local/lib/python3.10/dist-packages (0.4.12)\n",
            "Requirement already satisfied: fairscale==0.4.4 in /usr/local/lib/python3.10/dist-packages (0.4.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.0) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.0) (2.31.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.0) (0.1.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.0) (0.14.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.0) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.10/dist-packages (from timm==0.4.12) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm==0.4.12) (0.16.0+cu118)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.16.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.16.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.16.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.16.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.16.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.16.0) (2023.7.22)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.16.0) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.16.0) (1.3.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.4.12) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4->timm==0.4.12) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4->timm==0.4.12) (1.3.0)\n",
            "Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rank_bm25) (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "import sys\n",
        "\n",
        "%cd /content/drive/MyDrive/CSC2508/\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    if not os.path.isdir(\"/content/drive/MyDrive/CSC2508/CSC2508_final_project\"):\n",
        "        !git clone --recurse-submodule https://github.com/BenAgro314/CSC2508_final_project.git\n",
        "        %cd /content/drive/MyDrive/CSC2508/CSC2508_final_project\n",
        "    else:\n",
        "        %cd /content/drive/MyDrive/CSC2508/CSC2508_final_project\n",
        "        !git pull  --recurse-submodules\n",
        "\n",
        "    # install and clone requirments\n",
        "    !pip3 install transformers==4.16.0 timm==0.4.12 fairscale==0.4.4\n",
        "    !pip install rank_bm25\n",
        "\n",
        "from primitives.document import Document\n",
        "from primitives.corpus import Corpus\n",
        "from primitives.caption import Caption\n",
        "from utils.video_to_images import load_video_into_images\n",
        "import torch\n",
        "from pathlib import Path\n",
        "import time\n",
        "import tqdm\n",
        "import cv2\n",
        "from rank_bm25 import BM25Okapi\n",
        "import numpy as np\n",
        "sys.path.append(\"/content/drive/MyDrive/CSC2508/CSC2508_final_project/BLIP\")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "eRa-p0AEwMru",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRa-p0AEwMru",
        "outputId": "4f0e284e-2e2d-4365-a6d7-8a3284151958"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reshape position embedding from 196 to 576\n",
            "load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\n"
          ]
        }
      ],
      "source": [
        "from models.blip import blip_decoder\n",
        "\n",
        "image_size = 384\n",
        "\n",
        "model_url = 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth'\n",
        "\n",
        "model = blip_decoder(pretrained=model_url, image_size=image_size, vit='base', med_config=\"BLIP/configs/med_config.json\")\n",
        "model.eval()\n",
        "model = model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "FjtW78QvrwqY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjtW78QvrwqY",
        "outputId": "6607ba7e-4719-4214-c2d3-03c5042c5522"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unprocessed videos: {'People Swimming with Whale Shark'}\n",
            "Processing People Swimming with Whale Shark\n",
            "Video fps: 29.97002997002997, total frames: 461\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "31it [00:44,  1.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.000               a whale swimming in the ocean\n",
            "0.501               a whale swimming in the ocean\n",
            "1.001               a whale swimming in the ocean\n",
            "1.502               a whale swimming in the ocean\n",
            "2.002               a whale swimming in the ocean\n",
            "2.502               two people swimming with a whale\n",
            "3.003               a whale and a man swimming in the ocean\n",
            "3.504               two people swimming with a whale\n",
            "4.004               a whale swimming in the ocean\n",
            "4.505               a whale and its baby swimming in the ocean\n",
            "5.005               a whale swimming in the ocean\n",
            "5.506               a whale swimming in the ocean\n",
            "6.006               a whale swimming in the ocean\n",
            "6.506               a whale and a man swimming in the ocean\n",
            "7.007               a whale swimming in the ocean\n",
            "7.508               a whale and a whale in the ocean\n",
            "8.008               a whale and a whale in the ocean\n",
            "8.508               a whale and a penguin swimming in the ocean\n",
            "9.009               a whale swimming in the ocean\n",
            "9.510               two dolphins swimming in the ocean\n",
            "10.010              a whale swimming in the ocean\n",
            "10.511              a whale swimming in the ocean\n",
            "11.011              a whale swimming in the ocean\n",
            "11.511              a whale in the ocean\n",
            "12.012              a shark in the water\n",
            "12.513              a dolphin swimming in the ocean\n",
            "13.013              a whale swimming in the ocean\n",
            "13.514              a dolphin swimming in the ocean\n",
            "14.014              two dolphins swimming in the ocean\n",
            "14.514              a whale and a dolphin in the water\n",
            "15.015              a whale swimming in the ocean\n",
            "Documents: ['costa_rica_cropped', 'production 3694841', 'People Swimming with Whale Shark']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# preprocess videos into text\n",
        "\n",
        "video_path = \"/content/drive/MyDrive/CSC2508/videos/\"\n",
        "doc_path = \"/content/drive/MyDrive/CSC2508/documents/\"\n",
        "\n",
        "videos = {Path(v).stem: v for v in os.listdir(video_path)}\n",
        "docs = {Path(d).stem: d for d in os.listdir(doc_path)}\n",
        "\n",
        "assert len(docs) <= len(videos), f\"Documents {set(docs.keys()).difference(set(videos.keys()))} do not have corresponding videos\"\n",
        "unprocessed_vids = set(videos.keys()).difference(set(docs.keys()))\n",
        "print(f\"Unprocessed videos: {unprocessed_vids}\")\n",
        "\n",
        "for vid_name in unprocessed_vids:\n",
        "    vid_path = os.path.join(video_path, videos[vid_name])\n",
        "    print(f\"Processing {vid_name}\")\n",
        "\n",
        "    cap = cv2.VideoCapture(vid_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    document = Document(name=vid_name, video_path=vid_path, fps=fps)\n",
        "\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    cap.release()\n",
        "    print(f\"Video fps: {fps}, total frames: {total_frames}\")\n",
        "    subsample_rate = int(round(fps * 0.5)) # we want to read in videos at 2 fps\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for frame, img, pil_itmage in tqdm.tqdm(load_video_into_images(vid_path, image_size, device, subsample_rate)):\n",
        "\n",
        "            start_time = time.time()\n",
        "            caption = model.generate(img, sample=False, num_beams=3, max_length=20, min_length=5)\n",
        "            # print(f'inference time {time.time() - start_time:.3f} s')\n",
        "            #display(pil_image.resize((image_size, image_size)))\n",
        "            document.add_caption(frame=frame, caption=Caption(caption[0]))\n",
        "\n",
        "    print(document)\n",
        "    document.save(doc_path)\n",
        "\n",
        "corpus = Corpus(doc_path)\n",
        "print(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "RK6-GkBQ67Gb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RK6-GkBQ67Gb",
        "outputId": "a11777cd-e3b9-4459-abdc-9712d671502b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "costa_rica_cropped | a green tree frog | 1095\n"
          ]
        }
      ],
      "source": [
        "query = \"frog\"\n",
        "\n",
        "tokenized_query = query.split(\" \")\n",
        "corpus_bm25 = BM25Okapi(corpus.tokenize_documents())\n",
        "doc_scores = corpus_bm25.get_scores(tokenized_query)\n",
        "\n",
        "selected_doc = corpus[np.argmax(doc_scores)]\n",
        "\n",
        "doc_bm25 = BM25Okapi(selected_doc.tokenize_captions())\n",
        "caption_scores = doc_bm25.get_scores(tokenized_query)\n",
        "selected_caption = selected_doc[np.argmax(caption_scores)]\n",
        "\n",
        "\n",
        "print(selected_doc.name, \"|\", selected_caption[0], \"|\", selected_caption[1])\n",
        "cap = cv2.VideoCapture(selected_doc.video_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2yc2425-Ewd1",
      "metadata": {
        "id": "2yc2425-Ewd1"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open(selected_doc.video_path,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "start_time = selected_caption[1] / selected_doc.fps\n",
        "end_time = start_time + 5\n",
        "HTML(f\"\"\"\n",
        "<video width=400 controls autoplay>\n",
        "      <source src=\"{data_url}#t={start_time},{end_time}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
